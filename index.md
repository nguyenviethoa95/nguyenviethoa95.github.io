# Portfolio

---

## Natural Language Processing 
---
### RASA Chatbot
[![Generic badge](https://img.shields.io/badge/Open-Demo-Blue.svg)](https://shields.io/)  

Try the demo 

### Twitter Sentiment Analysis with BERT on EU-Solidarity
[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/assets/colab-badge.svg)

---
### Sentence similarity based on semantic nets and corpus statistics
<!---[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/detect-food-trends-facebook.html)-->
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/nguyenviethoa95/sentence_word_similarity-matrix/blob/main/sentence_word_similarity_matrix.ipynb)

<br/>
<br/>
<br/>

---
## Computer Vision
### Emoticon Generation with VAE 
[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1o1qmBDXCxMhZRncgdA_IdkVNalhIrsVg?usp=sharing)

---

### Emotion Recognition with Facial Landmark
[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1o1qmBDXCxMhZRncgdA_IdkVNalhIrsVg?usp=sharing)

<br />
<br />
<br />


## Software Engineering
---
### Blockchain

<div align="justify">
Prototype of a full stack solution that generates humidity  data using sensors, which is persisted  in the Hyperledger Fabric blockchain framework and visualizes the blockchain data using Flask.
</div >
Read our project's report [here](/pdf/Final Presentation.pdf)
<center><img src="images/hyperledgernetwork.png"/></center>
  
---

### Web Crawling
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/nguyenviethoa95/Baugenehmigung-Crawler)  
<div align="justify">
The use of the web crawler is inevitable when it comes to collecting massive data set. The use case for the web crawler implemented in this thesis is to extract information from an official announcement containing new building permissions. While running web crawler on a local machine is fine or do-once tasks, and a small amount of data, where the crawling process can be triggered manually. However, this is not a sustainable, and reliable solution  for retrieving a huge amount of data. Web crawler can be optimized with deploying into the cloud to reduce operational management and increase parallelism. Cloud computing also provides greater flexibility in term of computing capacity, and IP address.
</div>
Read my thesis [here](/pdf/BachelorThesis.pdf)
<center><img src="images/thesis2.png"/></center>
